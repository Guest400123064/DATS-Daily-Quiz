{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DATS Daily Quiz Session One: ML-Basics\n",
    "\n",
    "[Quiz Source](https://www.1point3acres.com/bbs/thread-713903-1-1.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Day 1, 03-25-2021\n",
    "\n",
    "**Question:** Explain the concepts of *Overfitting* and *Underfitting*\n",
    "\n",
    "**Ans from Web:** \n",
    "* *Overfitting:* Overfitting refers to a model that models the training data too well. Overfitting happens when a model **learns the detail and noise in the training data** to the extent that it negatively impacts the performance of the model on new data (test set). This means that the **noise or random fluctuations in the training data is picked up and learned as concepts by the model.** The problem is that **these concepts DO NOT apply to new data** and negatively impact the models **ability to generalize.** Overfitting is more likely with nonparametric and nonlinear models that **have more flexibility** when learning a target function. As such, many nonparametric machine learning algorithms also include parameters or techniques to **limit and constrain how much detail the model learns.** For example, decision trees are a nonparametric machine learning algorithm that is very flexible and is subject to overfitting training data. This problem can be addressed by **pruning a tree** after it has learned in order to remove some of the detail it has picked up.\n",
    "* *Underfitting:* Underfitting refers to a model that can neither model the training data nor generalize to new data.\n",
    "An underfit machine learning model is not a suitable model and will be obvious as it will have poor performance on the training data.\n",
    "Underfitting is often not discussed as it is easy to detect given a good performance metric. The remedy is to move on and try alternate machine learning algorithms. Nevertheless, it does provide a good contrast to the problem of overfitting.\n",
    "\n",
    "**In a Nutshell:**\n",
    "* *Overfitting:* The resulting model has much higher performance on the training set than on the test set, as it learns ungeneralizable details/noises as \"concepts\" that belong to the training set only. Flexible models, e.g. non-parametric models like decision trees, are usually prone to this problem.\n",
    "* *Underfitting:* Underfitting refers to a model that can neither model the training data nor generalize to new data.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Day 2, 03-26-2021\n",
    "\n",
    "**Question:** Explain the notion of *Variance-Bias Trade-off*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}